# SignLanguageRecognition
 Developed Python backend plus interactive frontend application that classifies ASL alphabets in real time with built-in audio-translation, interprets hand-gesture based on motion recognition, and provides logistical insights page on model confidence and accuracy
 Employed OpenCV to collect data samples of ASL alphabet, pre-processed data using Numpy and Pandas, trained data using Tensorflow/Keras APIs and implemented computer vision algorithms with OpenCV and Mediapipe libraries

<img width="743" alt="Screenshot 2024-01-27 at 5 16 33 PM" src="https://github.com/aditi-jain1/SignLanguageRecognition/assets/134651538/ab0ac2a4-23b4-4b36-9f10-e3487c876cda">
